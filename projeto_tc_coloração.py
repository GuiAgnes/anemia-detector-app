# -*- coding: utf-8 -*-
"""Projeto TC -  Coloração.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1J96tdWHG-4Dt8bbCt8Proptfp82TRr4N
"""

# CÉLULA 1: Instalação e Importação de Bibliotecas
print("--- CÉLULA 1: Importando Bibliotecas ---")

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Model
from tensorflow.keras.applications import EfficientNetB0, EfficientNetB3
from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.utils import class_weight
import os
from PIL import Image

# Verificação de GPU
device_name = tf.test.gpu_device_name()
if "GPU" not in device_name:
    print("AVISO: GPU não encontrada. Treinando em CPU (lento).")
else:
    print(f"GPU encontrada: {device_name}")

# CÉLULA 2: Parâmetros Principais do Pipeline
print("\n--- CÉLULA 2: Configurando Parâmetros ---")

# --- Escolha do Modelo ---
MODEL_CHOICE = 'B0' # 'B0' (rápido) ou 'B3' (mais robusto)

# --- Parâmetros de Treinamento ---
USE_AGGRESSIVE_AUG = True  # True para usar rotação e mudança de cor
USE_CLASS_WEIGHTS = True   # True para balancear classes desproporcionais
FINE_TUNE = True           # True para refinar o modelo na Fase 2

# --- Parâmetros Gerais ---
IMG_HEIGHT = 224 if MODEL_CHOICE == 'B0' else 300
IMG_WIDTH = 224 if MODEL_CHOICE == 'B0' else 300
IMG_CHANNELS = 3
INPUT_SHAPE = (IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)
CLASSES = ['Normal', 'Leve', 'Moderada', 'Grave']
N_CLASSES = len(CLASSES)

# --- Hiperparâmetros ---
BATCH_SIZE = 32
EPOCHS_PHASE_1 = 30
LEARNING_RATE = 1e-4

# --- Fine-Tuning ---
FINE_TUNE_EPOCHS = 15
FINE_TUNE_LR = 1e-5

# --- Configuração CSV ---
COLUNA_ID_CSV = 'ID'

# CÉLULA 3: Montagem do Drive e Definição de Caminhos
print("\n--- CÉLULA 3: Montando Google Drive ---")

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# --- Caminhos (Ajuste conforme sua estrutura) ---
BASE_PATH = "/content/drive/MyDrive/projeto_tc_ovinos/classificacaoMucosa/"
LABEL_FILE_PATH = os.path.join(BASE_PATH, "FAMACHA.csv")
MODEL_OUTPUT_DIR = os.path.join(BASE_PATH, "Modelos_Salvos")
os.makedirs(MODEL_OUTPUT_DIR, exist_ok=True)

print(f"Pasta Base: {BASE_PATH}")
print(f"Arquivo de Rótulos: {LABEL_FILE_PATH}")
print(f"Saída dos Modelos: {MODEL_OUTPUT_DIR}")

# CÉLULA 4: Carregando, Processando e Dividindo Dados
print("\n--- CÉLULA 4: Carregando e Processando Dados ---")

# 1. Ler CSV
try:
    df_excel = pd.read_csv(LABEL_FILE_PATH, sep=';', dtype={COLUNA_ID_CSV: str})
    df_excel = df_excel.rename(columns={COLUNA_ID_CSV: 'ID_Ovelha'})
    print("CSV carregado com sucesso.")
except Exception as e:
    print(f"ERRO AO LER CSV: {e}")
    raise

# 2. Escanear Imagens (Pastas Numéricas)
print(f"Escaneando imagens em: {BASE_PATH}")
image_data = []

for folder_name in os.listdir(BASE_PATH):
    folder_path = os.path.join(BASE_PATH, folder_name)
    # Verifica se é uma pasta e se o nome é um número (ID da ovelha)
    if os.path.isdir(folder_path) and folder_name.isdigit():
        id_ovelha = folder_name
        try:
            for file_name in os.listdir(folder_path):
                if file_name.lower().endswith(('.png', '.jpg', '.jpeg')):
                    filepath = os.path.join(folder_path, file_name)
                    image_data.append({'ID_Ovelha': id_ovelha, 'filepath': filepath})
        except Exception as e:
            print(f"  Erro na pasta {folder_name}: {e}")

df_imagens = pd.DataFrame(image_data)
if df_imagens.empty:
    raise ValueError("ERRO: Nenhuma imagem encontrada. Verifique os caminhos.")

# 3. Merge (Imagens + Rótulos)
df = pd.merge(df_imagens, df_excel, on='ID_Ovelha')

# 4. Categorizar Hematócrito
def categorize_hematocrit(ht_value):
    try:
        if isinstance(ht_value, str): ht_value = ht_value.replace(',', '.')
        ht_value = float(ht_value)
    except: return 'Indefinido'

    if ht_value < 15: return 'Grave'
    elif 15 <= ht_value <= 20: return 'Moderada'
    elif 21 <= ht_value <= 26: return 'Leve'
    elif ht_value >= 27: return 'Normal'
    return 'Indefinido'

df['classe'] = df['hematocrito'].apply(categorize_hematocrit)
df = df[df['classe'] != 'Indefinido']

print(f"Dataset Final: {len(df)} imagens válidas.")
print(df['classe'].value_counts())

# 5. DIVISÃO DOS DADOS (TRAIN / VAL / TEST)
# 70% Treino, 15% Validação, 15% Teste
print("\nDividindo dataset...")
train_df, temp_df = train_test_split(df, test_size=0.30, stratify=df['classe'], random_state=42)
val_df, test_df = train_test_split(temp_df, test_size=0.50, stratify=temp_df['classe'], random_state=42)

print(f"Treino: {len(train_df)} | Validação: {len(val_df)} | Teste: {len(test_df)}")

# CÉLULA 5: Data Augmentation e Generators
print("\n--- CÉLULA 5: Configurando Data Augmentation ---")

if USE_AGGRESSIVE_AUG:
    print("Modo: Augmentation Agressivo")
    train_datagen = ImageDataGenerator(
        rescale=1./255.,
        rotation_range=20,
        zoom_range=[0.85, 1.15],
        width_shift_range=0.1,
        height_shift_range=0.1,
        shear_range=0.1,
        brightness_range=[0.8, 1.2],
        horizontal_flip=True,
        vertical_flip=True,
        fill_mode='nearest'
    )

else:
    print("Modo: Augmentation Leve")
    train_datagen = ImageDataGenerator(
        rescale=1./255.,
        rotation_range=10,
        horizontal_flip=True,
        fill_mode='nearest'
    )

# Apenas rescale para Val/Test
val_test_datagen = ImageDataGenerator(rescale=1./255.)

# Geradores
train_generator = train_datagen.flow_from_dataframe(
    train_df, x_col='filepath', y_col='classe',
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE, class_mode='categorical', classes=CLASSES, shuffle=True
)

validation_generator = val_test_datagen.flow_from_dataframe(
    val_df, x_col='filepath', y_col='classe',
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE, class_mode='categorical', classes=CLASSES, shuffle=False
)

test_generator = val_test_datagen.flow_from_dataframe(
    test_df, x_col='filepath', y_col='classe',
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    batch_size=BATCH_SIZE, class_mode='categorical', classes=CLASSES, shuffle=False
)

# CÉLULA 6: Construindo o Modelo
print("\n--- CÉLULA 6: Construindo Arquitetura ---")

def build_model(model_choice='B0', input_shape=INPUT_SHAPE, n_classes=N_CLASSES):
    if model_choice == 'B0':
        base_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=input_shape)
        name = 'efficientnetb0'
    else:
        base_model = EfficientNetB3(include_top=False, weights='imagenet', input_shape=input_shape)
        name = 'efficientnetb3'

    base_model.trainable = False # Congela na Fase 1

    inputs = tf.keras.Input(shape=input_shape)
    x = base_model(inputs, training=False)
    x.name = name

    x = GlobalAveragePooling2D()(x)
    x = Dropout(0.3)(x)
    x = Dense(256, activation='relu')(x)
    x = BatchNormalization()(x)
    outputs = Dense(n_classes, activation='softmax')(x)

    return Model(inputs, outputs), name

model, BASE_MODEL_NAME = build_model(MODEL_CHOICE)
model.summary()

# CÉLULA 7: Treinamento Fase 1
print("\n--- CÉLULA 7: Fase 1 (Transfer Learning) ---")

METRICS = ['accuracy', tf.keras.metrics.Precision(name='precision'), tf.keras.metrics.Recall(name='recall')]

# Callbacks
checkpoint_path = os.path.join(MODEL_OUTPUT_DIR, "best_anemia_model.keras")
callbacks = [
    ModelCheckpoint(checkpoint_path, monitor='val_loss', save_best_only=True, verbose=1),
    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1),
    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, verbose=1)
]

# Pesos de Classe
class_weights = None
if USE_CLASS_WEIGHTS:
    y_train = train_generator.classes
    weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)
    class_weights = dict(zip(np.unique(y_train), weights))
    print(f"Pesos calculados: {class_weights}")

# Compilar e Treinar
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),
              loss='categorical_crossentropy', metrics=METRICS)

history_1 = model.fit(
    train_generator,
    epochs=EPOCHS_PHASE_1,
    validation_data=validation_generator,
    callbacks=callbacks,
    class_weight=class_weights
)

# CÉLULA 8: Fase 2 (Fine-Tuning)
print("\n--- CÉLULA 8: Fase 2 (Fine-Tuning) ---")

history_2 = None

if FINE_TUNE:
    # Carregar melhor estado da Fase 1
    try:
        model.load_weights(checkpoint_path)
        print("Melhor modelo da Fase 1 carregado.")
    except: pass

    # Descongelar base
    base_layer = model.get_layer(BASE_MODEL_NAME)
    base_layer.trainable = True

    # Congelar as primeiras camadas (estabilidade)
    freeze_until = int(len(base_layer.layers) * 0.75)
    for layer in base_layer.layers[:freeze_until]:
        layer.trainable = False
    print(f"Descongeladas as camadas a partir de {freeze_until}.")

    # Recompilar com LR menor
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=FINE_TUNE_LR),
                  loss='categorical_crossentropy', metrics=METRICS)

    # Treinar novamente
    total_epochs = EPOCHS_PHASE_1 + FINE_TUNE_EPOCHS
    history_2 = model.fit(
        train_generator,
        epochs=total_epochs,
        initial_epoch=history_1.epoch[-1] + 1,
        validation_data=validation_generator,
        callbacks=callbacks,
        class_weight=class_weights
    )

# CÉLULA 9: Avaliação Final e Gráficos
print("\n--- CÉLULA 9: Avaliação ---")

def plot_history(h1, h2=None):
    acc = h1.history['accuracy']
    val_acc = h1.history['val_accuracy']
    loss = h1.history['loss']
    val_loss = h1.history['val_loss']

    if h2:
        acc += h2.history['accuracy']
        val_acc += h2.history['val_accuracy']
        loss += h2.history['loss']
        val_loss += h2.history['val_loss']

    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.plot(acc, label='Treino Acc')
    plt.plot(val_acc, label='Val Acc')
    plt.title('Acurácia')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(loss, label='Treino Loss')
    plt.plot(val_loss, label='Val Loss')
    plt.title('Loss')
    plt.legend()
    plt.show()

plot_history(history_1, history_2)

# Carregar o melhor modelo de TODAS as fases
print("Carregando melhor modelo final...")
best_model = tf.keras.models.load_model(checkpoint_path)

# Evaluate
results = best_model.evaluate(test_generator)
print(f"Resultados no Teste: Loss={results[0]:.4f}, Acc={results[1]:.4f}")

# CÉLULA 10: Métricas Detalhadas
print("\n--- CÉLULA 10: Relatórios ---")

y_pred_prob = best_model.predict(test_generator)
y_pred = np.argmax(y_pred_prob, axis=1)
y_true = test_generator.classes

# Get the mapping from class index to class name
class_idx_to_name = {v: k for k, v in test_generator.class_indices.items()}

# Filter class_names to only include classes present in y_true
unique_true_labels = np.unique(y_true)
filtered_class_names = [class_idx_to_name[idx] for idx in unique_true_labels]

print(classification_report(y_true, y_pred, target_names=filtered_class_names))

cm = confusion_matrix(y_true, y_pred)
plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=filtered_class_names, yticklabels=filtered_class_names)
plt.xlabel('Previsto')
plt.ylabel('Real')
plt.show()

# CÉLULA 11: Exportar Modelos
print("\n--- CÉLULA 11: Salvando Modelos ---")

# Salvar Keras/H5
h5_path = os.path.join(MODEL_OUTPUT_DIR, "anemia_model_final.h5")
keras_path = os.path.join(MODEL_OUTPUT_DIR, "anemia_model_final.keras")
# best_model.save(h5_path) # Removido para evitar TypeError
best_model.save(keras_path)
print(f"Salvo: {keras_path}")

# Converter para TFLite (Otimizado)
converter = tf.lite.TFLiteConverter.from_keras_model(best_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

tflite_path = os.path.join(MODEL_OUTPUT_DIR, "anemia_model_final.tflite")
with open(tflite_path, 'wb') as f:
    f.write(tflite_model)

# Comparar Tamanhos
k_size = os.path.getsize(keras_path) / (1024*1024)
t_size = os.path.getsize(tflite_path) / (1024*1024)
print(f"Keras: {k_size:.2f} MB | TFLite: {t_size:.2f} MB")
print("Processo Finalizado!")

# CÉLULA 12: Visualização de Predições e Exportação
print("\n--- CÉLULA 12: Visualização e Exportação ---")

# --- 12.1: Visualização de Predições ---
print("Mostrando algumas predições do conjunto de teste...")
images, labels = next(iter(test_generator))
preds_probs = best_model.predict(images)
preds = np.argmax(preds_probs, axis=1)
true_labels = np.argmax(labels, axis=1)
class_names = list(test_generator.class_indices.keys())

plt.figure(figsize=(15, 10))
for i in range(min(12, len(images))): # Plotar até 12 imagens
    plt.subplot(3, 4, i+1)
    plt.imshow(images[i])
    true_class = class_names[true_labels[i]]
    pred_class = class_names[preds[i]]
    color = "green" if true_class == pred_class else "red"
    plt.title(f"Verdadeiro: {true_class}\nPrevisto: {pred_class}", color=color)
    plt.axis('off')
plt.tight_layout()
plt.show()

# --- 12.2: Exportação Final (.keras e .tflite) ---
print(f"Salvando e convertendo o modelo final para: {MODEL_OUTPUT_DIR}")

h5_path = os.path.join(MODEL_OUTPUT_DIR, "anemia_model_final.h5")
keras_path = os.path.join(MODEL_OUTPUT_DIR, "anemia_model_final.keras")
tflite_path = os.path.join(MODEL_OUTPUT_DIR, "anemia_model_final.tflite")

best_model.save(h5_path)
best_model.save(keras_path)
print(f"Modelos salvos em {keras_path} e {h5_path}")

# Converter para TensorFlow Lite (TFLite)
converter = tf.lite.TFLiteConverter.from_keras_model(best_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()

with open(tflite_path, 'wb') as f:
    f.write(tflite_model)
print(f"Modelo TFLite (otimizado) salvo em {tflite_path}")

try:
    keras_size = os.path.getsize(keras_path) / (1024 * 1024) # em MB
    tflite_size = os.path.getsize(tflite_path) / (1024 * 1024) # em MB
    print("\n--- Comparação de Tamanho ---")
    print(f"Modelo .keras: {keras_size:.2f} MB")
    print(f"Modelo .tflite: {tflite_size:.2f} MB")
    print(f"Redução: {(1 - tflite_size / keras_size) * 100:.1f}%")
except Exception as e:
    print(f"Erro ao calcular tamanhos: {e}")

print("\n--- Pipeline de Treinamento e Avaliação Concluído ---")